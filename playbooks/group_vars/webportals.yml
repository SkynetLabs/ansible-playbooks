---
# =============================================================================
# Ansible become passwords

# Set secrets storage var prefix
# `secrets_storage` var (defined in ansible-private repository) can contain
# value with hyphen, e.g. `hashicorp-vault` to use for loading task files. For
# loading secrets storage specific vars we need to replace `-` with `_`
secrets_storage_var_prefix: "{{ secrets_storage | replace('-', '_') }}"

# User password candidate (will be used if not set otherwise, e.g. during
# secrets storage migrations)
ansible_become_pass_candidate: "{{ lookup('password', '/dev/null chars=ascii_letters,digits length=32') }}"

# User password hash to be used on user creation
user_pass_hash: >-
  {{
    ansible_become_pass
    | password_hash('sha512', 65534 | random(seed=inventory_hostname)
    | string)
  }}

# =============================================================================
# Portal setup settings (from fresh server)

# Setup basic security
setup_basic_security: True

# User settings
webportal_user: "user"
webportal_user_authorized_keys: ""
webportal_temp_user: "userdance"
access_check_timeout_secs: 5

initial_users:
  - username: "{{ webportal_user }}"
    uid: 1000
    password_hash: "{{ user_pass_hash }}"
    authorized_keys: "{{ webportal_user_authorized_keys }}"

# Security settings
# geerlingguy.security role vars
security_sudoers_passworded: "{{ [webportal_user] }}"
security_autoupdate_enabled: False
security_fail2ban_enabled: True

# Server settings
# Timezone
webportal_server_set_timezone: True
webportal_server_timezone: "UTC"
# Update server hostname to inventory hostname
webportal_update_hostname: True

# geerlingguy.docker role vars
docker_users: "{{ [webportal_user] }}"

# UFW firewall settings
setup_ufw: True
group_ufw_rules:
  # yamllint disable-line rule:braces
  - { rule: "allow", port: "80", proto: "tcp", direction: "in" }
  # yamllint disable-line rule:braces
  - { rule: "allow", port: "443", proto: "tcp", direction: "in" }
ufw_deny_outgoing_to_local_network: True
local_networks_allowed:
  - "10.10.10.10/24"
local_networks_denied:
  - "10.0.0.0/8"
  - "172.16.0.0/12"
  - "192.168.0.0/16"
  - "100.64.0.0/10"
  - "198.18.0.0/15"
  - "169.254.0.0/16"

# Iptables: Tor exit nodes blocking
block_tor_exit_nodes: True
block_tor_exit_nodes_lists:
  torproject:
    url: "https://check.torproject.org/torbulkexitlist?ip="
    filename: "torproject-exitnodelist"
    ipset_ipv4: "torproject-exitnodelist-ipv4"
  dan:
    url: "https://www.dan.me.uk/torlist/?exit"
    filename: "dan-exitnodelist"
    ipset_ipv4: "dan-exitnodelist-ipv4"
    ipset_ipv6: "dan-exitnodelist-ipv6"
  # Downloads from dan.me.uk are limited to once per 30 mins (= 1800 secs), we
  # do not redownload the given number of seconds to prevent errors loading
  # error message instead of IP list to ipset. During downloading Tor lists
  # the script saves timestamps to two temporary files, one for each list. If
  # we try to redownload manually or via cron job sooner than the below defined
  # interval, the script skips redownloading the lists. i.e. it is safe to run
  # the script e.g. every 5 minutes, but the redownloads and ipset updates are
  # performed only after the last download is older then the below interval.
  do_not_redownload_within_secs: 2000

# Plaintext secrets storage settings

# `ansible-private` repository path inside Ansible Control Machine container
plaintext_base_dir: "/tmp"
plaintext_repository_dir: "ansible-private"

plaintext_secrets_dir: "plaintext-secrets"
plaintext_ansible_dir: "{{ plaintext_repository_dir }}/{{ plaintext_secrets_dir }}"

plaintext_portal_credentials_server_subfolder: "portal-server-credentials"
plaintext_portal_credentials_server: "{{ plaintext_ansible_dir }}/{{ plaintext_portal_credentials_server_subfolder }}/{{ webportal_user + '@' + ansible_host }}"

plaintext_portal_config_common_subfolder: "portal-common-configs"
plaintext_portal_config_cluster_subfolder: "portal-cluster-configs"

# See my-vars/config-sample-do-not-edit.yml file for documentation.
plaintext_portal_common_and_cluster_configs_list:
  # - "{{ plaintext_ansible_dir }}/{{ plaintext_portal_config_common_subfolder }}/common.yml"
  - "{{ plaintext_ansible_dir }}/{{ plaintext_portal_config_cluster_subfolder }}/cluster-{{ portal_cluster_id }}.yml"

plaintext_portal_config_server_subfolder: "portal-server-configs"
plaintext_portal_config_server: "{{ plaintext_ansible_dir }}/{{ plaintext_portal_config_server_subfolder }}/{{ inventory_hostname }}.yml"

plaintext_accounts_jwks_json: "{{ plaintext_ansible_dir }}/{{ plaintext_portal_config_cluster_subfolder }}/cluster-{{ portal_cluster_id }}-jwks.json"

# HashiCorp Vault settings

# For security reasons Ansible lookup returns AnsibleUnsafeString, we have to
# handle this otherwise Jinja templates refuse to process the unsafe string.
hashicorp_vault_url: "{{ lookup('env', 'HCV_URL', allow_unsafe=True) | first }}"
hashicorp_vault_token: "{{ lookup('env', 'HCV_TOKEN', allow_unsafe=True) | first }}"

hashicorp_vault_storage_backend_dir: "kv/data"
hashicorp_vault_ansible_dir: "ansible-skynet"
hashicorp_vault_portal_credentials_server_subfolder: "portal-server-credentials"
hashicorp_vault_portal_credentials_server: "{{ hashicorp_vault_ansible_dir }}/{{ hashicorp_vault_portal_credentials_server_subfolder }}/{{ webportal_user + '@' + ansible_host }}"
hashicorp_vault_portal_credentials_server_incl_backend_dir: "{{ hashicorp_vault_storage_backend_dir }}/{{ hashicorp_vault_portal_credentials_server }}"

hashicorp_vault_portal_config_common_subfolder: "portal-common-configs"
hashicorp_vault_portal_config_cluster_subfolder: "portal-cluster-configs"

# See my-vars/config-sample-do-not-edit.yml file for documentation.
hashicorp_vault_portal_common_and_cluster_configs_list:
  # - "{{ hashicorp_vault_ansible_dir }}/{{ hashicorp_vault_portal_config_common_subfolder }}/common.yml"
  - "{{ hashicorp_vault_ansible_dir }}/{{ hashicorp_vault_portal_config_cluster_subfolder }}/cluster-{{ portal_cluster_id }}.yml"

hashicorp_vault_portal_config_server_subfolder: "portal-server-configs"
hashicorp_vault_portal_config_server: "{{ hashicorp_vault_ansible_dir }}/{{ hashicorp_vault_portal_config_server_subfolder }}/{{ inventory_hostname }}.yml"

hashicorp_vault_accounts_jwks_json: "{{ hashicorp_vault_ansible_dir }}/{{ hashicorp_vault_portal_config_cluster_subfolder }}/cluster-{{ portal_cluster_id }}-jwks.json"

# LastPass settings
lastpass_ansible_dir: "Shared-Ansible"

# lastpass has different separators based on the account. Because that makes
# total sense and everyone's lives easier. The file separator is defined as the
# path separator between a directory and file, i.e. dir/file. The directory
# separator is the path separator between directories, i.e. dir/subdir.
#
# The file separator appears to always be a forward slash /
#
# The directory separator appears to change based on Shared folders for
# business accounts and folders for personal accounts. Ansible uses the lpass
# cli tool, and the lpass cli tool shows a path separator of a forward slash
# '/' for Shared folders under business accounts and shows a path separator of
# backslash '\' for personal folders, non-shared folders. Depending on way to
# print the output, backslash can be printed as single or double backslash in
# debug messages and logs in Ansible.
lastpass_directory_separator: '{{ "/" if "Shared" in lastpass_ansible_dir else backslash_char }}'
lastpass_file_separator: "/"

lastpass_portal_credentials_server_subfolder: "portal-server-credentials"
lastpass_portal_credentials_server: "{{ lastpass_ansible_dir }}{{ lastpass_directory_separator }}{{ lastpass_portal_credentials_server_subfolder }}{{ lastpass_file_separator }}{{ webportal_user + '@' + ansible_host }}"

lastpass_portal_config_common_subfolder: "portal-common-configs"
lastpass_portal_config_cluster_subfolder: "portal-cluster-configs"

# See my-vars/config-sample-do-not-edit.yml file for documentation.
lastpass_portal_common_and_cluster_configs_list:
  # - "{{ lastpass_ansible_dir }}{{ lastpass_directory_separator }}{{ lastpass_portal_config_common_subfolder }}{{ lastpass_file_separator }}common.yml"
  - "{{ lastpass_ansible_dir }}{{ lastpass_directory_separator }}{{ lastpass_portal_config_cluster_subfolder }}{{ lastpass_file_separator }}cluster-{{ portal_cluster_id }}.yml"

lastpass_portal_config_server_subfolder: "portal-server-configs"
lastpass_portal_config_server: "{{ lastpass_ansible_dir }}{{ lastpass_directory_separator }}{{ lastpass_portal_config_server_subfolder }}{{ lastpass_file_separator }}{{ inventory_hostname }}.yml"

lastpass_accounts_jwks_json: "{{ lastpass_ansible_dir }}{{ lastpass_directory_separator }}{{ lastpass_portal_config_cluster_subfolder }}{{ lastpass_file_separator }}cluster-{{ portal_cluster_id }}-jwks.json"

# Portal paths settings
#
# NOTE: These paths are not strictly alphabetized due to top level paths needing
# to be defined first so that sub paths can reference them. When possible, the
# paths are alphabetized if there is no reference order that needs to be
# maintained.
#
# Webportal Paths
webportal_user_home_dir: "/home/{{ webportal_user }}"
webportal_dir: "{{ webportal_user_home_dir }}/skynet-webportal"
webportal_docker_dir: "{{ webportal_dir }}/docker"
webportal_docker_data_dir: "{{ webportal_docker_dir }}/data"
webportal_cron_file: "{{ webportal_dir }}/setup-scripts/support/crontab"
webportal_logrotated_dir: "{{ webportal_dir }}/setup-scripts/logrotate.d"
elasticsearch_data_data_dir: "{{ webportal_docker_data_dir }}/elasticsearch/data"

# Sia Paths
sia_data_dir: "{{ webportal_docker_data_dir }}/sia"

# Accounts Paths
accounts_conf_dir: "{{ webportal_docker_dir }}/accounts/conf"
accounts_jwks_path: "{{ accounts_conf_dir }}/jwks.json"

# Mongo Paths
mongo_data_dir: "{{ webportal_docker_data_dir }}/mongo"
mongo_backups_dir: "{{ mongo_data_dir }}/backups"
mongo_db_dir: "{{ mongo_data_dir }}/db"
mongo_mgkey_file: "{{ mongo_data_dir }}/mgkey"

# Devops Paths
devops_dir: "{{ webportal_user_home_dir }}/devops"
devops_scripts_dir: "{{ devops_dir }}/scripts"
block_tor_exit_nodes_script_file: "{{ devops_scripts_dir }}/tor-blocklists-update.sh"
logs_dir: "{{ devops_dir }}/logs"
setup_status_dir: "{{ devops_dir }}/setup"
setup_status_file: "{{ setup_status_dir }}/status"

# Certbot paths
certbot_docker_data_dir: "{{ webportal_docker_data_dir }}/certbot"
cloudflare_ini_file: "{{ certbot_docker_data_dir }}/cloudflare.ini"

# Default service ports
default_mongo_port: 27017

# Docker prune settings
docker_prune_timeout_secs: 1800

# Sia setup settings
# Wallet initialization
use_existing_sia_seed_if_exists: True

# MongoDB constants
mongo_max_voting_members: 7

# =============================================================================
# Skynet webportal role settings

webportal_repo_url: "https://github.com/SkynetLabs/skynet-webportal.git"
docker_skyd_repo_url: "https://github.com/SkynetLabs/docker-skyd.git"
accounts_repo_url: "https://github.com/SkynetLabs/skynet-accounts.git"
dotfiles_repo_url: "https://gitlab.com/NebulousLabs/dotfiles.git"

# TODO: default in role: False
webportal_setup_dotfiles_and_dev_tools: True

# TODO: move to role default vars
webportal_allowance:
  amount: 10KS
  expected_storage: 10TB
  expected_upload: 4TB
  expected_download: 2TB
  expected_redundancy: 5
  max_contract_price: 1SC
  max_sector_access_price: 5SC
  max_storage_price: 500SC
  payment_contract_initial_funding: 10SC
  period: 8640b

# TODO: move to role default vars
webportal_server_config_defaults:
  sia_wallet_password: ""
  sia_api_port: 9980
  sia_api_password: "{{ lookup('pipe','openssl rand -base64 32') }}"
  hsd_api_key: "{{ lookup('pipe','openssl rand -base64 32') }}"
  server_uid: "{{ lookup('pipe','openssl rand -hex 8') }}"
  accounts_test_user_email: "{{ lookup('pipe','openssl rand -hex 8') }}@example.com"
  accounts_test_user_password: "{{ lookup('pipe','openssl rand -hex 8') }}"
  accounts_test_user_api_key: "not-defined"

# TODO: move to role default vars
# This variable sets default values for common/cluster settings if they are not
# defined by portal operator in common/cluster records defined by
# {{ secrets_storage_var_prefix }}_portal_common_and_cluster_configs_list.
webportal_common_config_defaults:
  s3_backup_path: ""
  abuse_log_level: "info"
  abuse_ncmec_reporting_enabled: False
  accounts_log_level: "info"
  blocker_log_level: "info"
  cookie_hash_key: "{{ lookup('pipe','openssl rand -hex 32') }}"
  cookie_enc_key: "{{ lookup('pipe','openssl rand -hex 32') }}"
  mongo_db_mgkey: "{{ lookup('pipe','openssl rand -base64 756') }}"
  skynet_db_host: "mongo"
  skynet_db_pass: "{{ lookup('pipe','openssl rand -base64 32') }}"
  skynet_db_port: "{{ default_mongo_port }}"
  skynet_db_replicaset: "{{ portal_cluster_id }}"
  skynet_db_user: "admin"

# TODO: move to role default vars
# TODO: default to: False
webportal_setup_health_checks: True

# =============================================================================
# Portal deploy settings (on running server)

webportal_config_files:
  - "docker-compose.override.yml"
  - ".env"

# generic vars
alpine_image: alpine:3.16.2

# skynet-js vars
skynet_js_org_and_repo: "SkynetLabs/skynet-js"
skynet_js_repo_url: "https://github.com/{{ skynet_js_org_and_repo }}.git"
skynet_js_repo_api_url: "https://api.github.com/repos/{{ skynet_js_org_and_repo }}"
skynet_js_docker_test_image: "node:18-alpine"

# skynet-accounts vars
oathkeeper_docker_image: "oryd/oathkeeper:v0.39"

# Local git checkouts
local_temp_skynetlabs_git_repos: "/tmp/SkynetLabs-ansible/git-repos"
local_temp_skynetlabs_git_repos_skynet_js: "{{ local_temp_skynetlabs_git_repos }}/skynet-js"

# Registry access, downloads and uploads waits
# How long to wait for active registry access, downloads and uploads to finish (in seconds)
# before shutting down the docker services after disabling the health checks.
renter_busy_check_wait_secs: 300

# Health checks
portal_health_check_disable_delay_secs: 0
# Disable portal when free disk space is lower then x GiB (60 GiB recommended)
portal_health_check_disable_free_disk_space_limit_bytes: "{{ 60e+9 | int }}"

# Waiting for sia consensus sync, sia full setup and /daemon/ready
sia_consensus_sync_check_delays_secs: 5
sia_consensus_sync_timeout_secs: 900
sia_full_setup_timeout_secs: 60
sia_daemon_ready_timeout_secs: 600
curl_docker_image: "curlimages/curl:7.77.0"
sia_endpoint_not_available_msg: "491 Module disabled - Refer to API.md"

# Waiting for docker services
# Do not wait for these docker services
docker_services_exclude_waiting:
  - "kratos-migrate"
# Minumum time we wait for checking docker services to be running and not
# restarting. Should be > 60 seconds, because docker container might appear
# running correctly and then restart after 60 seconds.
docker_services_min_non_restarting_time_in_secs: 65

# Localhost vars
# my-logs path relative to ./playbooks directory
local_logs_dir: "../my-logs"
# Path relative to ./playbooks/vars directory
private_vars_file: "../../../ansible-private/private-vars/private-vars.yml"

# renter_log_lines defines the strings to match with sed to remove from the sia
# renter.log file
renter_log_lines:
  - "pt not ready yet for worker"
  - "HEALTH LOOP VERBOSE"
  - "dirupdatebatch completed"

# Host migrations, sync
rsync_docker_image: "instrumentisto/rsync-ssh:alpine3.15-r0"

# Abuse Scanner vars
cypress_docker_image: "cypress/included:10.3.0"
